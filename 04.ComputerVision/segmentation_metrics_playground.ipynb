{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 13})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Metrics\n",
    "\n",
    "For each metric I implement a Numpy and a Keras version, and verify that they give the same results. Examples are input images with a squares and circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_np(y_true, y_pred, metric_name, metric_type='standard', drop_last = True, mean_per_class=False, verbose=False):\n",
    "    \"\"\" \n",
    "    Compute mean metrics of two segmentation masks, via numpy.\n",
    "    \n",
    "    IoU(A,B) = |A & B| / (| A U B|)\n",
    "    Dice(A,B) = 2*|A & B| / (|A| + |B|)\n",
    "    \n",
    "    Args:\n",
    "        y_true: true masks, one-hot encoded.\n",
    "        y_pred: predicted masks, either softmax outputs, or one-hot encoded.\n",
    "        metric_name: metric to be computed, either 'iou' or 'dice'.\n",
    "        metric_type: one of 'standard' (default), 'soft', 'naive'.\n",
    "          In the standard version, y_pred is one-hot encoded and the mean\n",
    "          is taken only over classes that are present (in y_true or y_pred).\n",
    "          The 'soft' version of the metrics are computed without one-hot \n",
    "          encoding y_pred.\n",
    "          The 'naive' version return mean metrics where absent classes contribute\n",
    "          to the class mean as 1.0 (instead of being dropped from the mean).\n",
    "        drop_last = True: boolean flag to drop last class (usually reserved\n",
    "          for background class in semantic segmentation)\n",
    "        mean_per_class = False: return mean along batch axis for each class.\n",
    "        verbose = False: print intermediate results such as intersection, union\n",
    "          (as number of pixels).\n",
    "    Returns:\n",
    "        IoU/Dice of y_true and y_pred, as a float, unless mean_per_class == True\n",
    "          in which case it returns the per-class metric, averaged over the batch.\n",
    "    \n",
    "    Inputs are B*W*H*N tensors, with\n",
    "        B = batch size,\n",
    "        W = width,\n",
    "        H = height,\n",
    "        N = number of classes\n",
    "    \"\"\"\n",
    "    \n",
    "    assert y_true.shape == y_pred.shape, 'Input masks should be same shape, instead are {}, {}'.format(y_true.shape, y_pred.shape)\n",
    "    assert len(y_pred.shape) == 4, 'Inputs should be B*W*H*N tensors, instead have shape {}'.format(y_pred.shape)\n",
    "    \n",
    "    flag_soft = (metric_type == 'soft')\n",
    "    flag_naive_mean = (metric_type == 'naive')\n",
    "    \n",
    "    num_classes = y_pred.shape[-1]\n",
    "    # if only 1 class, there is no background class and it should never be dropped\n",
    "    drop_last = drop_last and num_classes>1\n",
    "    \n",
    "    if not flag_soft:\n",
    "        if num_classes>1:\n",
    "            # get one-hot encoded masks from y_pred (true masks should already be in correct format, do it anyway)\n",
    "            y_pred = np.array([ np.argmax(y_pred, axis=-1)==i for i in range(num_classes) ]).transpose(1,2,3,0)\n",
    "            y_true = np.array([ np.argmax(y_true, axis=-1)==i for i in range(num_classes) ]).transpose(1,2,3,0)\n",
    "        else:\n",
    "            y_pred = (y_pred > 0).astype(int)\n",
    "            y_true = (y_true > 0).astype(int)\n",
    "    \n",
    "    # intersection and union shapes are batch_size * n_classes (values = area in pixels)\n",
    "    axes = (1,2) # W,H axes of each image\n",
    "    intersection = np.sum(np.abs(y_pred * y_true), axis=axes) # or, np.logical_and(y_pred, y_true) for one-hot\n",
    "    mask_sum = np.sum(np.abs(y_true), axis=axes) + np.sum(np.abs(y_pred), axis=axes)\n",
    "    union = mask_sum  - intersection # or, np.logical_or(y_pred, y_true) for one-hot\n",
    "    \n",
    "    if verbose:\n",
    "        print('intersection (pred*true), intersection (pred&true), union (pred+true-inters), union (pred|true)')\n",
    "        print(intersection, np.sum(np.logical_and(y_pred, y_true), axis=axes), union, np.sum(np.logical_or(y_pred, y_true), axis=axes))\n",
    "    \n",
    "    smooth = .001\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    dice = 2*(intersection + smooth)/(mask_sum + smooth)\n",
    "    \n",
    "    metric = {'iou': iou, 'dice': dice}[metric_name]\n",
    "    \n",
    "    # define mask to be 0 when no pixels are present in either y_true or y_pred, 1 otherwise\n",
    "    mask =  np.not_equal(union, 0).astype(int)\n",
    "    # mask = 1 - np.equal(union, 0).astype(int) # True = 1\n",
    "    \n",
    "    if drop_last:\n",
    "        metric = metric[:,:-1]\n",
    "        mask = mask[:,:-1]\n",
    "    \n",
    "    # return mean metrics: remaining axes are (batch, classes)\n",
    "    # if mean_per_class, average over batch axis only\n",
    "    # if flag_naive_mean, average over absent classes too\n",
    "    if mean_per_class:\n",
    "        if flag_naive_mean:\n",
    "            return np.mean(metric, axis=0)\n",
    "        else:\n",
    "            # mean only over non-absent classes in batch (still return 1 if class absent for whole batch)\n",
    "            return (np.sum(metric * mask, axis=0) + smooth)/(np.sum(mask, axis=0) + smooth)\n",
    "    else:\n",
    "        if flag_naive_mean:\n",
    "            return np.mean(metric)\n",
    "        else:\n",
    "            # mean only over non-absent classes\n",
    "            class_count = np.sum(mask, axis=0)\n",
    "            return np.mean(np.sum(metric * mask, axis=0)[class_count!=0]/(class_count[class_count!=0]))\n",
    "        \n",
    "def mean_iou_np(y_true, y_pred, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute mean Intersection over Union of two segmentation masks, via numpy.\n",
    "    \n",
    "    Calls metrics_np(y_true, y_pred, metric_name='iou'), see there for allowed kwargs.\n",
    "    \"\"\"\n",
    "    return metrics_np(y_true, y_pred, metric_name='iou', **kwargs)\n",
    "\n",
    "def mean_dice_np(y_true, y_pred, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute mean Dice coefficient of two segmentation masks, via numpy.\n",
    "    \n",
    "    Calls metrics_np(y_true, y_pred, metric_name='dice'), see there for allowed kwargs.\n",
    "    \"\"\"\n",
    "    return metrics_np(y_true, y_pred, metric_name='dice', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras version\n",
    "def seg_metrics(y_true, y_pred, metric_name, metric_type='standard', drop_last = True, mean_per_class=False, verbose=False):\n",
    "    \"\"\" \n",
    "    Compute mean metrics of two segmentation masks, via Keras.\n",
    "    \n",
    "    IoU(A,B) = |A & B| / (| A U B|)\n",
    "    Dice(A,B) = 2*|A & B| / (|A| + |B|)\n",
    "    \n",
    "    Args:\n",
    "        y_true: true masks, one-hot encoded.\n",
    "        y_pred: predicted masks, either softmax outputs, or one-hot encoded.\n",
    "        metric_name: metric to be computed, either 'iou' or 'dice'.\n",
    "        metric_type: one of 'standard' (default), 'soft', 'naive'.\n",
    "          In the standard version, y_pred is one-hot encoded and the mean\n",
    "          is taken only over classes that are present (in y_true or y_pred).\n",
    "          The 'soft' version of the metrics are computed without one-hot \n",
    "          encoding y_pred.\n",
    "          The 'naive' version return mean metrics where absent classes contribute\n",
    "          to the class mean as 1.0 (instead of being dropped from the mean).\n",
    "        drop_last = True: boolean flag to drop last class (usually reserved\n",
    "          for background class in semantic segmentation)\n",
    "        mean_per_class = False: return mean along batch axis for each class.\n",
    "        verbose = False: print intermediate results such as intersection, union\n",
    "          (as number of pixels).\n",
    "    Returns:\n",
    "        IoU/Dice of y_true and y_pred, as a float, unless mean_per_class == True\n",
    "          in which case it returns the per-class metric, averaged over the batch.\n",
    "    \n",
    "    Inputs are B*W*H*N tensors, with\n",
    "        B = batch size,\n",
    "        W = width,\n",
    "        H = height,\n",
    "        N = number of classes\n",
    "    \"\"\"\n",
    "    \n",
    "    flag_soft = (metric_type == 'soft')\n",
    "    flag_naive_mean = (metric_type == 'naive')\n",
    "    \n",
    "    # always assume one or more classes\n",
    "    num_classes = K.shape(y_true)[-1]\n",
    "        \n",
    "    if not flag_soft:\n",
    "        # get one-hot encoded masks from y_pred (true masks should already be one-hot)\n",
    "        y_pred = K.one_hot(K.argmax(y_pred), num_classes)\n",
    "        y_true = K.one_hot(K.argmax(y_true), num_classes)\n",
    "\n",
    "    # if already one-hot, could have skipped above command\n",
    "    # keras uses float32 instead of float64, would give error down (but numpy arrays or keras.to_categorical gives float64)\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "\n",
    "    # intersection and union shapes are batch_size * n_classes (values = area in pixels)\n",
    "    axes = (1,2) # W,H axes of each image\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=axes)\n",
    "    mask_sum = K.sum(K.abs(y_true), axis=axes) + K.sum(K.abs(y_pred), axis=axes)\n",
    "    union = mask_sum  - intersection # or, np.logical_or(y_pred, y_true) for one-hot\n",
    "\n",
    "    smooth = .001\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    dice = 2 * (intersection + smooth)/(mask_sum + smooth)\n",
    "\n",
    "    metric = {'iou': iou, 'dice': dice}[metric_name]\n",
    "\n",
    "    # define mask to be 0 when no pixels are present in either y_true or y_pred, 1 otherwise\n",
    "    mask =  K.cast(K.not_equal(union, 0), 'float32')\n",
    "    \n",
    "    if drop_last:\n",
    "        metric = metric[:,:-1]\n",
    "        mask = mask[:,:-1]\n",
    "    \n",
    "    if verbose:\n",
    "        print('intersection, union')\n",
    "        print(K.eval(intersection), K.eval(union))\n",
    "        print(K.eval(intersection/union))\n",
    "    \n",
    "    # return mean metrics: remaining axes are (batch, classes)\n",
    "    if flag_naive_mean:\n",
    "        return K.mean(metric)\n",
    "\n",
    "    # take mean only over non-absent classes\n",
    "    class_count = K.sum(mask, axis=0)\n",
    "    non_zero = tf.greater(class_count, 0)\n",
    "    non_zero_sum = tf.boolean_mask(K.sum(metric * mask, axis=0), non_zero)\n",
    "    non_zero_count = tf.boolean_mask(class_count, non_zero)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Counts of inputs with class present, metrics for non-absent classes')\n",
    "        print(K.eval(class_count), K.eval(non_zero_sum / non_zero_count))\n",
    "        \n",
    "    return K.mean(non_zero_sum / non_zero_count)\n",
    "\n",
    "def mean_iou(y_true, y_pred, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute mean Intersection over Union of two segmentation masks, via Keras.\n",
    "\n",
    "    Calls metrics_k(y_true, y_pred, metric_name='iou'), see there for allowed kwargs.\n",
    "    \"\"\"\n",
    "    return seg_metrics(y_true, y_pred, metric_name='iou', **kwargs)\n",
    "\n",
    "def mean_dice(y_true, y_pred, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute mean Dice coefficient of two segmentation masks, via Keras.\n",
    "\n",
    "    Calls metrics_k(y_true, y_pred, metric_name='iou'), see there for allowed kwargs.\n",
    "    \"\"\"\n",
    "    return seg_metrics(y_true, y_pred, metric_name='dice', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input images\n",
    "I will build simple geometrical figures and use those as \"objects\" for assessing segmentation metrics. For example, see below how to generate circles and diamonds with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.meshgrid(np.arange(-7,7.1), np.arange(-7,7.1))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize = (13,4))\n",
    "\n",
    "# ax1.contourf(x, y, circle, alpha=0.5)\n",
    "# # ax1.scatter(x, y, circle)\n",
    "# for i in range(len(x)):\n",
    "#     for j in range(len(y)):\n",
    "#         ax1.text(x[i][j], y[i][j], '%d'% circle[i][j], ha='center', va='center')\n",
    "\n",
    "circle_fuzzy = np.minimum([1], np.maximum([0], 25-x**2-y**2)/20)\n",
    "\n",
    "ax1.contourf(x, y, circle_fuzzy, alpha=0.4, vmin=0, vmax=1)\n",
    "# ax1.scatter(x, y, circle_fuzzy)\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(y)):\n",
    "        fmt = '%d' if circle_fuzzy[i][j] %1 ==0 else '%1.1f'\n",
    "        ax1.text(x[i][j], y[i][j], fmt % circle_fuzzy[i][j] , ha='center', va='center')\n",
    "\n",
    "diamond = np.minimum([1], np.maximum([0], (3 - abs(x)) + (3 - abs(y)))/3)\n",
    "\n",
    "ax2.contourf(x,y,diamond, alpha=0.4, vmin=0, vmax=1)\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(y)):\n",
    "        fmt = '%d' if diamond[i][j] %1 ==0 else '%1.1f'\n",
    "        ax2.text(x[i][j], y[i][j], fmt % diamond[i][j] , ha='center', va='center')\n",
    "\n",
    "for ax in (ax1, ax2): ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation masks - for now only do object (circle, diamonds), will add background later on. Truth value mask is zero/one outside/inside of object. Predicted mask has continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_circle(xy=(0,0), r=4, fuzz_factor=0.8):\n",
    "    x0, y0 = xy\n",
    "    max_fuzz = fuzz_factor * r**2\n",
    "    circle = np.minimum([1], np.maximum([0], r**2 - (x-x0)**2 - (y-y0)**2)/max_fuzz)\n",
    "    \n",
    "    return circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_diamond(xy=(0,0), r=2, fuzz_factor=1.5):\n",
    "    x0, y0 = xy\n",
    "    max_fuzz = fuzz_factor * r\n",
    "    diamond = np.minimum([1], np.maximum([0], (r - abs(x-x0)) + (r-abs(y-y0)))/max_fuzz)\n",
    "    \n",
    "    return diamond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_grid = np.meshgrid(np.arange(-7,7.1,0.05), np.arange(-7,7.1,0.05))\n",
    "x,y = fine_grid\n",
    "\n",
    "zz = fuzzy_circle((2,0), r=3, fuzz_factor=0.1)\n",
    "plt.contour(x, y, zz, levels = [0.99], colors='b')\n",
    "zz = fuzzy_circle((1,1))\n",
    "plt.contourf(x, y, zz, alpha=0.5, levels=[0,0.25,0.5,0.75,0.99,1.25], cmap = 'gray_r')\n",
    "zz = fuzzy_diamond(xy=(-3.5,-3.5))\n",
    "plt.contourf(x, y, zz, alpha=0.5, levels=[0,0.25,0.5,0.75,0.99,1.25], cmap = 'gray_r')\n",
    "plt.gca().set_aspect(1)\n",
    "plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute IoU and Dice metrics for series of two overlapping circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize = (13,4))\n",
    "params = [((0,0), 4), ((2,0), 4, ), ((2,0), 2) ]\n",
    "y_true = fuzzy_circle(fuzz_factor=0.01)\n",
    "\n",
    "print('{:<10s} {:<10s} {:<10s}'.format('','explicit', 'np function'))\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    axes[i].scatter(0,0, c='b')\n",
    "    axes[i].add_artist(plt.Circle((0, 0), 4.05, lw=2, edgecolor='b', facecolor=(0,0,1,0.3), zorder=1))\n",
    "    xy, r = params[i]\n",
    "    axes[i].scatter(*xy, c='r')\n",
    "    axes[i].add_artist(plt.Circle(xy, r, lw=2, ls='--', edgecolor='r', facecolor=(1,0,0,0.3), zorder=1))\n",
    "    \n",
    "    smooth = 0.001\n",
    "    y_pred = fuzzy_circle(xy, r, 0.01)\n",
    "    intersection = np.sum(np.logical_and(y_true, y_pred))\n",
    "    union = np.sum(np.logical_or(y_pred, y_true))\n",
    "    iou = np.mean((intersection)/union)\n",
    "    dice = 2*np.mean(intersection/(np.sum(y_pred)+np.sum(y_true)))\n",
    "    \n",
    "    print('{:<10s} {:<10.2f} {:<10.2f}'.format('IoU', iou, metrics_np(np.reshape(y_true, (1,)+y_true.shape+(1,)), np.reshape(y_pred, (1,)+y_pred.shape+(1,)), metric_name = 'iou')))\n",
    "    print('{:<10s} {:<10.2f} {:<10.2f}'.format('Dice', dice, metrics_np(np.reshape(y_true, (1,)+y_true.shape+(1,)), np.reshape(y_pred, (1,)+y_pred.shape+(1,)), metric_name = 'dice')))\n",
    "    \n",
    "    axes[i].text(0,5, f'IoU={iou:1.2f}\\nDice={dice:1.2f}', ha='center')\n",
    "    \n",
    "    axes[i].set_axis_off()\n",
    "    axes[i].set(aspect=1, xlim=(-5,6.1), ylim=(-5,6))\n",
    "fig.savefig('metrics_iou_dice.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = fine_grid\n",
    "fig, axes = plt.subplots(1,4, figsize = (16,4))\n",
    "params = [((0,0), 4, 0.8), ((0,0), 4, 1), ((2,0), 4, 0.8), ((2,0), 2, 0.8) ]\n",
    "y_true = fuzzy_circle(fuzz_factor=0.01)\n",
    "\n",
    "print('{:<10s} {:<10s} {:<10s}'.format('','explicit', 'np function'))\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    # axes[i].contour(x, y, y_true, levels = [0.99], colors='b')\n",
    "    axes[i].add_artist(plt.Circle((0, 0), 4, lw=2, edgecolor='b', facecolor=(0,0,0,0), zorder=1))\n",
    "    xy, r, fuzz_factor = params[i]\n",
    "    y_pred = fuzzy_circle(xy, r, fuzz_factor)\n",
    "    # axes[i].contourf(x, y, y_pred, alpha=0.5, levels=[0.01,0.5,0.99,1.25], cmap = 'gray_r')\n",
    "    axes[i].pcolormesh(x, y, y_pred, alpha=0.3, shading='gouraud', cmap = 'gray_r')\n",
    "    cs = axes[i].contour(x, y, y_pred, levels=[0.01,0.5,0.99,1.25], colors = 'k')\n",
    "    axes[i].clabel(cs, fmt='%1.1f')\n",
    "    \n",
    "    intersection = np.sum(np.logical_and(y_true, y_pred))\n",
    "    union = np.sum(np.logical_or(y_pred, y_true))\n",
    "    iou = np.mean(intersection/union)\n",
    "    \n",
    "    intersection_soft = np.sum(np.abs(y_true * y_pred))\n",
    "    union_soft = np.sum(np.abs(y_pred)) + np.sum(np.abs(y_true)) - intersection_soft\n",
    "    iou_soft = np.mean(intersection_soft/union_soft)\n",
    "\n",
    "    print('{:<10s} {:<10.2f} {:<10.2f}'.format('IoU',iou, metrics_np(np.reshape(y_true, (1,)+y_true.shape+(1,)), np.reshape(y_pred, (1,)+y_pred.shape+(1,)), metric_name='iou')))\n",
    "    print('{:<10s} {:<10.2f} {:<10.2f}'.format('soft IoU',iou_soft, metrics_np(np.reshape(y_true, (1,)+y_true.shape+(1,)), np.reshape(y_pred, (1,)+y_pred.shape+(1,)),metric_name='iou', metric_type='soft')))\n",
    "    \n",
    "    axes[i].text(0,5, f'IoU={iou:1.2f}\\nsoft IoU={iou_soft:1.2f}', ha='center')\n",
    "    \n",
    "    axes[i].set_axis_off()\n",
    "    axes[i].set(aspect=1)\n",
    "fig.savefig('metrics_iou_dice_soft.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = fuzzy_circle(fuzz_factor=0.01)\n",
    "y_pred = fuzzy_circle((2,0), 4, 0.8)\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(9,3))\n",
    "for ax in axes:\n",
    "    ax.set_axis_off(); ax.set(aspect=1)\n",
    "    ax.add_artist(plt.Circle((0, 0), 4, lw=2, edgecolor='b', facecolor=(0,0,0,0), zorder=1))\n",
    "    ax.text(-2,4,'True\\n mask', ha='center', va='bottom', color='b')\n",
    "    ax.add_artist(plt.Circle((2, 0), 4, lw=2, edgecolor='r', facecolor=(0,0,0,0), zorder=1))\n",
    "    ax.text(4,4,'Predicted\\n mask', ha='center', va='bottom', color='r')\n",
    "    iax=list(axes).index(ax)\n",
    "    if iax>0:\n",
    "        axes[iax].annotate(['hard ','soft '][iax-1]+'intersection', (1,-2), xytext=(0,-6), ha='center', arrowprops={'arrowstyle': '->', 'color':'y'}, zorder=2)\n",
    "        \n",
    "axes[0].pcolormesh(x,y, y_pred, cmap='gray_r')\n",
    "axes[1].pcolormesh(x,y, np.logical_and(y_true, y_pred), cmap='gray_r')\n",
    "axes[2].pcolormesh(x,y, y_true * y_pred, cmap='gray_r');\n",
    "fig.savefig('metrics_intersection_soft.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the non-naive mean_IoU, I need multiple classes, the masks of which overlap for only a small subset. I will arbitrarily take a circle and a diamond as examples of two classes, offset them a little and then find the IoU's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x,y = fine_grid\n",
    "true1 = fuzzy_circle(xy=(2,0), fuzz_factor=0.01)\n",
    "pred1 = fuzzy_circle(xy=(3,0))\n",
    "# two instances of Diamond class: first has IoU=0.33 (half overlap), second one has IoU=0.24\n",
    "true2 = fuzzy_diamond(xy=(-4,-2),r=1,fuzz_factor=0.01)  + fuzzy_diamond(xy=(-3.5,3),r=1,fuzz_factor=0.01)\n",
    "pred2 = fuzzy_diamond(xy=(-5,-3),r=1) + fuzzy_diamond(xy=(-5,3),r=1)\n",
    "empty = np.zeros_like(true1)\n",
    "\n",
    "plt.contour(x,y,true1, colors='r')\n",
    "plt.contour(x,y,true2, colors='b')\n",
    "\n",
    "plt.pcolormesh(x,y,pred1, cmap=mpl.colors.ListedColormap([(0,0,0,0)]+list(map(plt.get_cmap('Oranges'), range(256)))[1:]))\n",
    "plt.pcolormesh(x,y,pred2, cmap=mpl.colors.ListedColormap([(0,0,0,0)]+list(map(plt.get_cmap('Purples'), range(256)))[1:]))\n",
    "plt.gca().set_axis_off()\n",
    "plt.gca().set(aspect=1)\n",
    "\n",
    "y_true = np.expand_dims(np.stack([true1, true2, empty, empty, (true1==0) & (true2==0).astype(int)], axis=-1), axis=0)\n",
    "y_pred = np.expand_dims(np.stack([pred1, pred2, empty, empty, (pred1==0) & (pred2==0).astype(int)], axis=-1), axis=0)\n",
    "\n",
    "print('{:<60s} {:.3f}'.format('IoU of first class:', metrics_np(y_true[:,:,:,:1], y_pred[:,:,:,:1], metric_name='iou')))\n",
    "print('{:<60s} {:.3f}'.format('IoU of second class:', metrics_np(y_true[:,:,:,1:2], y_pred[:,:,:,1:2], metric_name='iou')))\n",
    "print('{:<60s} {:.3f}'.format('IoU of background:', metrics_np(y_true[:,:,:,-1:], y_pred[:,:,:,-1:], metric_name='iou')))\n",
    "print('{:<60s} {}'.format('IoU of each class (explicit list):', metrics_np(y_true, y_pred, metric_name='iou', metric_type='naive', drop_last=False, mean_per_class=True)))\n",
    "print('{:<60s} {:.3f}'.format('mean IoU of all classes (no background, naive mean):', metrics_np(y_true, y_pred, metric_name='iou', metric_type='naive')))\n",
    "print('{:<60s} {:.3f}'.format('mean IoU of all classes (with background, naive mean):', metrics_np(y_true, y_pred, metric_name='iou', metric_type='naive', drop_last = False)))\n",
    "print('{:<60s} {:.3f}'.format('mean IoU of all non-absent classes (dropping background):', metrics_np(y_true, y_pred, metric_name='iou')))\n",
    "\n",
    "plt.text(5,6,'Circle\\nIoU={:1.2f}'.format(metrics_np(y_true[:,:,:,:1], y_pred[:,:,:,:1], metric_name='iou')), color='r', ha='center', va='center')\n",
    "plt.text(-5,6,'Diamond\\nIoU={:1.2f}'.format(metrics_np(y_true[:,:,:,1:2], y_pred[:,:,:,1:2], metric_name='iou')), color='b', ha='center', va='center')\n",
    "plt.text(0,-5,'mean IoU={:1.2f}'.format(metrics_np(y_true, y_pred, metric_name='iou')), ha='center', va='bottom');\n",
    "\n",
    "plt.savefig('metrics_mean_iou_multiclass.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far I have used `batch_size=1`. Test the difference between naive and standard ways to take the mean, for multiple examples. Here I will take two images, the first with two classes as above and the second one with only the circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.stack([np.stack([true1, true2, empty, empty, (true1==0) & (true2==0).astype(int)], axis=-1),\n",
    "                   np.stack([true1, empty, empty, empty, (true1==0)], axis=-1)])\n",
    "y_pred = np.stack([np.stack([pred1, pred2, empty, empty, (pred1==0) & (pred2==0).astype(int)], axis=-1),\n",
    "                   np.stack([pred1, empty, empty, empty, (pred1==0)], axis=-1)])\n",
    "\n",
    "print('Naive per-class mean:    {}  --  Overall mean: {:1.2f}'.format(\n",
    "    metrics_np(y_true, y_pred, metric_name='iou', metric_type='naive', mean_per_class=True), \n",
    "    metrics_np(y_true, y_pred, metric_name='iou', metric_type='naive')))\n",
    "print('Standard per-class mean: {}  --  Overall mean: {:1.2f}'.format(\n",
    "    metrics_np(y_true, y_pred, metric_name='iou', mean_per_class=True), \n",
    "    metrics_np(y_true, y_pred, metric_name='iou')))\n",
    "print('Standard per-class mean, with background', metrics_np(y_true, y_pred, metric_name='iou', mean_per_class=True, drop_last=False))\n",
    "# metrics_np(y_true, y_pred, metric_name='iou', mean_per_class=True),\\\n",
    "# metrics_np(y_true, y_pred, metric_name='iou'),\\\n",
    "print('Soft per-class mean    ', metrics_np(y_true, y_pred, metric_name='iou', metric_type='soft', mean_per_class=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Keras version and verify it gives same result as Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hard IoU   {:1.6f} {:1.6f}'.format(metrics_np(y_true, y_pred, metric_name='iou'), \n",
    "                                        K.eval(seg_metrics(y_true, y_pred, metric_name='iou'))))\n",
    "print('soft IoU   {:1.6f} {:1.6f}'.format(metrics_np(y_true, y_pred, metric_name='iou', metric_type='soft'), \n",
    "                                        K.eval(seg_metrics(y_true, y_pred, metric_name='iou', metric_type='soft'))))\n",
    "print('hard IoU, naive mean {:1.6f} {:1.6f}'.format(metrics_np(y_true, y_pred, metric_name='iou', metric_type='naive'), \n",
    "                                                  K.eval(seg_metrics(y_true, y_pred, metric_name='iou', metric_type='naive'))))\n",
    "print('hard Dice   {:1.6f} {:1.6f}'.format(metrics_np(y_true, y_pred, metric_name='dice'), \n",
    "                                        K.eval(seg_metrics(y_true, y_pred, metric_name='dice'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print verbose info for metrics: look at number of pixels in intersection, union for each class and each input (`batch * classes` axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_np(y_true, y_pred, metric_name='iou', verbose=True),\\\n",
    "metrics_np(y_true, y_pred, metric_name='iou', metric_type='standard', mean_per_class=True),\\\n",
    "K.eval(seg_metrics(y_true, y_pred, metric_name='iou', verbose=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse-grained example\n",
    "\n",
    "Image with few pixels to explicitly check what is going on at the pixel level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.meshgrid(np.arange(-7,7.1,1), np.arange(-7,7.1,1))\n",
    "\n",
    "true1 = fuzzy_circle(xy=(2,0), fuzz_factor=0.01)\n",
    "pred1 = fuzzy_circle(xy=(3,0), fuzz_factor=1)\n",
    "# two instances of Diamond class: first has IoU=0.33 (half overlap), second one has IoU=0.24\n",
    "true2 = fuzzy_diamond(xy=(-4,-2),r=1,fuzz_factor=0.01)  + fuzzy_diamond(xy=(-3,3),r=1,fuzz_factor=0.01)\n",
    "pred2 = fuzzy_diamond(xy=(-5,-3),r=1) + fuzzy_diamond(xy=(-5,3),r=1)\n",
    "empty = np.zeros_like(true1)\n",
    "\n",
    "# build N*W*H*C ground truth and predicted masks\n",
    "y_true = np.stack([np.stack([true1, true2, empty, empty, (true1==0) & (true2==0).astype(int)], axis=-1),\n",
    "                   np.stack([true1, empty, empty, empty, (true1==0)], axis=-1)])\n",
    "y_pred = np.stack([np.stack([pred1, pred2, empty, empty, (pred1==0) & (pred2==0).astype(int)], axis=-1),\n",
    "                   np.stack([pred1, empty, empty, empty, (pred1==0)], axis=-1)])\n",
    "\n",
    "# plot predicted masks\n",
    "plt.pcolormesh(x,y,pred1, cmap=mpl.colors.ListedColormap([(0,0,0,0)]+list(map(plt.get_cmap('Oranges'), range(256)))[1:]))\n",
    "plt.pcolormesh(x,y,pred2, cmap=mpl.colors.ListedColormap([(0,0,0,0)]+list(map(plt.get_cmap('Purples'), range(256)))[1:]))\n",
    "\n",
    "# plot true masks\n",
    "plt.pcolormesh(x,y,true1, cmap=mpl.colors.ListedColormap([(0,0,0,0), (1,0,0,0.2)]))\n",
    "plt.pcolormesh(x,y,true2, cmap=mpl.colors.ListedColormap([(0,0,0,0), (0,0,1,0.2)]))\n",
    "\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(y)):\n",
    "        if pred1[i][j]!=0:\n",
    "            fmt = '%d' if pred1[i][j] %1 ==0 else '%1.1f'\n",
    "            plt.text(x[i][j]+0.5, y[i][j]+0.5, fmt % pred1[i][j] , ha='center', va='center')\n",
    "        if pred2[i][j]!=0:\n",
    "            fmt = '%d' if pred2[i][j] %1 ==0 else '%1.1f'\n",
    "            plt.text(x[i][j]+0.5, y[i][j]+0.5, fmt % pred2[i][j] , ha='center', va='center')\n",
    "\n",
    "plt.text(5,6,'Circles\\n(I,U)=({:},{:})\\nIoU={:1.2f}'.format(np.logical_and(pred1, true1).sum(), np.logical_or(pred1, true1).sum(),\n",
    "            metrics_np(y_true[:1,:,:,:1], y_pred[:1,:,:,:1], metric_name='iou')), color='r', ha='center', va='center')\n",
    "plt.text(-5.5,0.5,'Diamonds\\n(I,U)=({:},{:})\\nIoU={:1.2f}'.format(np.logical_and(pred2, true2).sum(), np.logical_or(pred2, true2).sum(),\n",
    "            metrics_np(y_true[:1,:,:,1:2], y_pred[:1,:,:,1:2], metric_name='iou')), color='b', ha='center', va='center')\n",
    "plt.text(0,-5,'mean IoU={:1.2f}'.format(metrics_np(y_true[:1], y_pred[:1], metric_name='iou')), ha='center', va='bottom');\n",
    "\n",
    "plt.gca().set_axis_off()\n",
    "# plt.gca().set(aspect=1)\n",
    "plt.savefig('metrics_mean_iou_coarse_example.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics_np(y_true, y_pred, metric_name='iou',verbose=True),\\\n",
    "metrics_np(y_true, y_pred, metric_name='iou', mean_per_class=True),\\\n",
    "K.eval(seg_metrics(y_true, y_pred, metric_name='iou', verbose=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "67d32777f905cb443c7595cdac206bb322335f5bfbf8ae9544bce83f7472f717"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
