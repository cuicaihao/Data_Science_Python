{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn-onnx: Convert your scikit-learn model into ONNX\n",
    "\n",
    "sklearn-onnx enables you to convert models from sklearn-learn toolkits into ONNX.\n",
    "\n",
    "- Introduction\n",
    "- Tutorial\n",
    "- API Summary\n",
    "- Gallery of examples\n",
    "- Convert a pipeline\n",
    "- Converters with options\n",
    "- Supported scikit-learn Models\n",
    "- Issues, questions\n",
    "\n",
    "You should look for existing issues or submit a new one. Sources are available on onnx/sklearn-onnx.\n",
    "\n",
    "## ONNX version\n",
    "\n",
    "The converter can convert a model for a specific version of ONNX. Every ONNX release is labelled with an opset number returned by function onnx_opset_version. This function returns the default value for parameter target opset (parameter target_opset) if it is not specified when converting the model. Every operator is versioned. The library chooses the most recent version below or equal to the targetted opset number for every operator. The ONNX model has one opset number for every operator domain, this value is the maximum opset number among all onnx nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx import __max_supported_opset__\n",
    "print(\"Last supported opset:\", __max_supported_opset__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backend\n",
    "\n",
    "sklearn-onnx converts models in ONNX format which can be then used to compute predictions with the backend of your choice. However, there exists a way to automatically check every converter with onnxruntime, onnxruntime-gpu. Every converter is tested with this backend.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick start\n",
    "\n",
    "ONNX Runtime provides an easy way to run machine learned models with high performance on CPU or GPU without dependencies on the training framework. Machine learning frameworks are usually optimized for batch training rather than for prediction, which is a more common scenario in applications, sites, and services. At a high level, you can:\n",
    "\n",
    "1. Train a model using your favorite framework.\n",
    "\n",
    "2. Convert or export the model into ONNX format. See ONNX Tutorials for more details.\n",
    "\n",
    "3. Load and run the model using ONNX Runtime.\n",
    "\n",
    "In this tutorial, we will briefly create a pipeline with scikit-learn, convert it into ONNX format and run the first predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Train a model using your favorite framework\n",
    "\n",
    "We’ll use the famous Iris datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clr = RandomForestClassifier()\n",
    "clr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris), iris.data.shape, iris.target.shape, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys(), iris.frame, iris.target_names, iris.feature_names, iris.data_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Convert or export the model into ONNX format\n",
    "ONNX is a format to describe the machine learned model. It defines a set of commonly used operators to compose models. There are tools to convert other model formats into ONNX. Here we will use ONNXMLTools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into ONNX format\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 4]))]\n",
    "onx = convert_sklearn(clr, initial_types=initial_type)\n",
    "with open(\"rf_iris.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the model size of the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh rf_iris.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load and run the model using ONNX Runtime\n",
    "We will use ONNX Runtime to compute the predictions for this machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction with ONNX Runtime\n",
    "import onnxruntime as rt\n",
    "import numpy\n",
    "sess = rt.InferenceSession(\"rf_iris.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onx = sess.run([label_name], {input_name: X_test.astype(numpy.float32)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_onx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module implements two functions: convert_sklearn and to_onnx. The first one was used in the previous examples, it requires two mandatory arguments:\n",
    "\n",
    "- a scikit-learn model or a pipeline\n",
    "- initial types\n",
    "\n",
    "scikit-learn does not store information about the training dataset. It is not always possible to retrieve the number of features or their types. That’s why the function needs another argument called initial_types. In many cases, the training datasets is a numerical matrix X_train. \n",
    "\n",
    "Then it becomes `initial_type=[('X', FloatTensorType([None, X_train.shape[1]]))]`. X is the name of this unique input, the second term indicates the type and shape. The shape is `[None, X_train.shape[1]]`, the first dimension is the number of rows followed by the number of features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows is undefined as the the number of requested predictions is unknown at the time the model is converted. The number of features is usually known. Let’s assume now the input is a string column followed by a matrix, then initial types would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "\n",
    "initial_type = [('X', FloatTensorType([None, 4]))]\n",
    "onx = to_onnx(clr, initial_types=initial_type)\n",
    "with open(\"rf_iris.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "import numpy\n",
    "sess = rt.InferenceSession(\"rf_iris.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onx = sess.run([label_name], {input_name: X_test.astype(numpy.float32)})\n",
    "\n",
    "type(pred_onx), pred_onx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related converters\n",
    "\n",
    "sklearn-onnx only converts models from scikit-learn. onnxmltools can be used to convert models for libsvm, lightgbm, xgboost. Other converters can be found on github/onnx, torch.onnx, ONNX-MXNet API, Microsoft.ML.Onnx…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and deploy a scikit-learn pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyquickhelper.helpgen.graphviz_helper import plot_graphviz\n",
    "import numpy\n",
    "from onnxruntime import InferenceSession\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor, RandomForestRegressor,\n",
    "    VotingRegressor)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skl2onnx import to_onnx\n",
    "from mlprodict.onnxrt import OnnxInference\n",
    "\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Train classifiers\n",
    "reg1 = GradientBoostingRegressor(random_state=1, n_estimators=5)\n",
    "reg2 = RandomForestRegressor(random_state=1, n_estimators=5)\n",
    "reg3 = LinearRegression()\n",
    "\n",
    "ereg = Pipeline(steps=[\n",
    "    ('voting', VotingRegressor([('gb', reg1), ('rf', reg2), ('lr', reg3)])),\n",
    "])\n",
    "ereg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converts the model\n",
    "The second argument gives a sample of the data used to train the model. It is used to infer the input type of the ONNX graph. It is converted into single float and ONNX runtimes may not fully support doubles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onx = to_onnx(ereg, X_train[:1].astype(numpy.float32),\n",
    "              target_opset=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with ONNX\n",
    "The first example uses onnxruntime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = InferenceSession(onx.SerializeToString())\n",
    "pred_ort = sess.run(None, {'X': X_test.astype(numpy.float32)})[0]\n",
    "\n",
    "pred_skl = ereg.predict(X_test.astype(numpy.float32))\n",
    "\n",
    "print(\"Onnx Runtime prediction:\\n\", pred_ort[:5])\n",
    "print(\"Sklearn rediction:\\n\", pred_skl[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "Before deploying, we need to compare that both scikit-learn and ONNX return the same predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(p1, p2):\n",
    "    p1 = p1.ravel()\n",
    "    p2 = p2.ravel()\n",
    "    d = numpy.abs(p2 - p1)\n",
    "    return d.max(), (d / numpy.abs(p1)).max()\n",
    "\n",
    "\n",
    "print(diff(pred_skl, pred_ort))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks good. Biggest errors (absolute and relative) are within the margin error introduced by using floats instead of doubles. We can save the model into ONNX format and compute the same predictions in many platform using onnxruntime."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8823236cafdf8838e553da22dc3cd99eabc27f67f79df71f7c8cf3bb2fe023dc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
