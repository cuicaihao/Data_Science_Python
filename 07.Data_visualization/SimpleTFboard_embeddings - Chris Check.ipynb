{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest introduction to embedding visualisation with Tensorboard\n",
    "\n",
    "Visualising embeddings is a powerful technique! It helps you understand what your algorithm learned, and if this is what you expected it to learn. Embedding visualisation is a standard feature in Tensorboard. Unfortunately many people on the internet seem to have some problems with getting a simple visualisation running. This is my attempt at creating the most simple code to get a simple visualisation of MNIST digits running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#LOG_DIR = './minimalsample'\n",
    "LOG_DIR = r'C:\\Users\\Chris.Cui\\Documents\\PythonScripts\\Simplest-Tensorflow-Tensorboard-MNIST-Embedding-Visualisation-master\\minimalsample'\n",
    "\n",
    "NAME_TO_VISUALISE_VARIABLE = \"mnistembedding\"\n",
    "\n",
    "TO_EMBED_COUNT = 5000\n",
    "\n",
    "\n",
    "path_for_mnist_sprites =  os.path.join(LOG_DIR,'mnistdigits.png')\n",
    "path_for_mnist_metadata =  os.path.join(LOG_DIR,'metadata.tsv')\n",
    "\n",
    "\n",
    "#path_for_mnist_sprites =   './minimalsample/mnistdigits.png'\n",
    "#path_for_mnist_metadata =   './minimalsample/metadata.tsv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to visualise\n",
    "Although the embedding visualiser is meant for visualising embeddings obtained after training, you can also use it to apply visualisation of normal MNIST digits. In this case, each digit is represented by a vector with length 28*28=784 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "batch_xs, batch_ys = mnist.train.next_batch(TO_EMBED_COUNT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the embeddings\n",
    "For this example the embeddings are extremely simple: they are the direct values of the traindata. Your graph will probably be more complicated, but the important thing is that you know the name of the variable you want to visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_var = tf.Variable(batch_xs, name=NAME_TO_VISUALISE_VARIABLE)\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the embedding projector\n",
    "This is the important part of your embedding visualisation. Here you specify what variable you want to project, what the metadata path is (the names and classes), and where you save the sprites. \n",
    "\n",
    "We will create the sprites later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_for_mnist_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "\n",
    "\n",
    "\n",
    "# Specify where you find the metadata\n",
    "embedding.metadata_path = path_for_mnist_metadata #'metadata.tsv'\n",
    "\n",
    "# Specify where you find the sprite (we will create this later)\n",
    "embedding.sprite.image_path = path_for_mnist_sprites #'mnistdigits.png'\n",
    "embedding.sprite.single_image_dim.extend([28,28])\n",
    "\n",
    "# Say that you want to visualise the embeddings\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data\n",
    "Tensorboard loads the saved variable from the saved graph. Initialise a session and variables, and save them in your logging directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation helper functions\n",
    "\n",
    "Mentioned above are the sprites. If you don't load sprites each digit is represented as a simple point (does not give you a lot of information). To add labels you have to create a 'sprite map': basically all images in what you want to visualise...\n",
    "\n",
    "There are three functions which are quite important for the visualisation: \n",
    "  - create_sprite_image: neatly aligns image sprits on a square canvas, as specified in the images section here:  (https://www.tensorflow.org/get_started/embedding_viz)\n",
    "  - vector_to_matrix_mnist: MNIST characters are loaded as a vector, not as an image... this function turns them into images\n",
    "  - invert_grayscale: matplotlib treats a 0 as black, and a 1 as white. The tensorboard embeddings visualisation looks way better with white backgrounds, so we invert them for the visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sprite_image(images):\n",
    "    \"\"\"Returns a sprite image consisting of images passed as argument. Images should be count x width x height\"\"\"\n",
    "    if isinstance(images, list):\n",
    "        images = np.array(images)\n",
    "    img_h = images.shape[1]\n",
    "    img_w = images.shape[2]\n",
    "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    \n",
    "    \n",
    "    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
    "    \n",
    "    for i in range(n_plots):\n",
    "        for j in range(n_plots):\n",
    "            this_filter = i * n_plots + j\n",
    "            if this_filter < images.shape[0]:\n",
    "                this_img = images[this_filter]\n",
    "                spriteimage[i * img_h:(i + 1) * img_h,\n",
    "                  j * img_w:(j + 1) * img_w] = this_img\n",
    "    \n",
    "    return spriteimage\n",
    "\n",
    "def vector_to_matrix_mnist(mnist_digits):\n",
    "    \"\"\"Reshapes normal mnist digit (batch,28*28) to matrix (batch,28,28)\"\"\"\n",
    "    return np.reshape(mnist_digits,(-1,28,28))\n",
    "\n",
    "def invert_grayscale(mnist_digits):\n",
    "    \"\"\" Makes black white, and white black \"\"\"\n",
    "    return 1-mnist_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the sprite image\n",
    "\n",
    "Pretty straightforward: convert our vectors to images, invert the grayscale, and create and save the sprite image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_visualise = batch_xs\n",
    "to_visualise = vector_to_matrix_mnist(to_visualise)\n",
    "to_visualise = invert_grayscale(to_visualise)\n",
    "\n",
    "sprite_image = create_sprite_image(to_visualise)\n",
    "\n",
    "plt.imsave(path_for_mnist_sprites,sprite_image,cmap='gray')\n",
    "plt.imshow(sprite_image,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the metadata\n",
    "To add colors to your mnist digits the embedding visualisation tool needs to know what label each image has. This is saved in a \"TSV (tab seperated file)\". \n",
    "\n",
    "Each line of our file contains the following: \n",
    "\n",
    "    \"Index\" , \"Label\" \n",
    "\n",
    "The Index is simply the index in our embedding matrix. The label is the label of the MNIST character. \n",
    "\n",
    "This code writes our data to the metadata file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_for_mnist_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_for_mnist_metadata,'w') as f:\n",
    "    f.write(\"Index\\tLabel\\n\")\n",
    "    for index,label in enumerate(batch_ys):\n",
    "        f.write(\"%d\\t%d\\n\" % (index,label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### How to run (https://imgur.com/a/4EFGZ)\n",
    "We saved our MNIST characters, time to visualise it! If you did not change any of the variables above you can run the visualisation with: \n",
    "\n",
    "tensorboard --logdir=minimalsample\n",
    "\n",
    "Now open a browser and navigate to http://127.0.0.1:6006 (note: this can change depending on your computer setup). You should see this after navigating to the Embeddings tab (note: if you have an older tensorflow version you will NOT see the Embeddings tab. This can only be resolved by upgradeing Tensorflow): \n",
    "\n",
    "![Imgur](http://i.imgur.com/THBeQwR.png)\n",
    "\n",
    "Click the embeddings tab to see the PCA of our MNIST digits. Click on the left on the \"color by\" selector and select the Label. You probably see some nice groupings (zeroes close to each other, sixes close to each other, etc.). \n",
    "\n",
    "![Imgur](http://i.imgur.com/5Qjjnt4.png)\n",
    "You can also try T-SNE to see the digits move around while they are trying to form groups. \n",
    "![Imgur](http://i.imgur.com/kIQ8juH.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Hopefully you now see that it is easy to add an embedding visualisation to your algorithm. Good luck visualising your own!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
