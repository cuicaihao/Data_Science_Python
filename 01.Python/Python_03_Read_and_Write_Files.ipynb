{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reading and Writing Files in Python"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section, we will learn some basic opearation about reading and writing files. Moreover, as a data scientist, building an accurate machine learning model is not the end of the project. We will showing you how to save and load your machine learning model in Python.This allows you to save your model to file and load it later in order to make predictions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read txt file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "txt_file_url = \"../data/files/Python.txt\"\n",
    "f = open(txt_file_url, \"r\") #opens file with name of \"Python.txt\"\n",
    "# read and print the entire file\n",
    "print(f.read())\n",
    "# remember to colse the file\n",
    "f.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Life is short,\n",
      "Use Python!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Used the **readline()** method twice, we would get the first 2 lines because of Python's reading process."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "f = open(txt_file_url, \"r\") #opens file with name of \"Python.txt\"\n",
    "# read the 1st line\n",
    "print(f.readline())\n",
    "# read the next line\n",
    "print(f.readline())\n",
    "f.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Life is short,\n",
      "\n",
      "Use Python!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#opens file with name of \"Python.txt\"\n",
    "f = open(\"files/Python.txt\", \"r\") \n",
    "myList = []\n",
    "for line in f:\n",
    "    myList.append(line)\n",
    "f.close()\n",
    "    \n",
    "print(myList)\n",
    "print(myList[0])\n",
    "print(myList[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Life is short,\\n', 'Use Python!']\n",
      "Life is short,\n",
      "\n",
      "Use Python!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write txt file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Write file with name of \"test.txt\"\n",
    "f = open(\"../data/files/test.txt\",\"w\")  \n",
    "f.write(\"I love Python.\\n\")\n",
    "f.write(\"I will be a Python master.\\n\")\n",
    "f.write(\"I need to keep learning!\")\n",
    "f.close()\n",
    "\n",
    "# read and see the test.txt file\n",
    "f = open(\"../data/files/test.txt\",\"r\") \n",
    "print(f.read())\n",
    "f.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I love Python.\n",
      "I will be a Python master.\n",
      "I need to keep learning!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read csv file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import csv\n",
    "csvFile = open(\"../data/files/test.csv\", \"r\") \n",
    "reader = csv.reader(csvFile, delimiter=',')\n",
    "# load the data in a dictionary \n",
    "result = {}\n",
    "for item in reader:\n",
    "    # ignore the first line\n",
    "    if reader.line_num == 1:\n",
    "        continue    \n",
    "    result[item[0]] = item[1]\n",
    "csvFile.close()\n",
    "\n",
    "print(result)    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Ali': '25', 'Bob': '24', 'Chirs': '29'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write csv file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import csv\n",
    "fileHeader = [\"name\", \"age\"]\n",
    "\n",
    "d1 = [\"Chris\", \"27\"]\n",
    "d2 = [\"Ming\", \"26\"]\n",
    "\n",
    "csvFile = open(\"../data/files/write.csv\", \"w\")\n",
    "writer = csv.writer(csvFile)\n",
    "writer = csv.writer(csvFile)\n",
    "\n",
    "# write the head and data\n",
    "writer.writerow(fileHeader)\n",
    "writer.writerow(d1)\n",
    "writer.writerow(d2)\n",
    "\n",
    "# Here is another command \n",
    "# writer.writerows([fileHeader, d1, d2])\n",
    "\n",
    "csvFile.close()\n",
    "\n",
    "# go to see the \"write.csv\" file."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can find more information from the [documentation](https://docs.python.org/3.6/library/csv.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using Pandas to Read CSV file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"../data/files/test.csv\")\n",
    "# data is data\n",
    "print(data) \n",
    "\n",
    "# extract the age data\n",
    "Age = np.array(data.Age, dtype = 'double')\n",
    "print(Age)\n",
    "\n",
    "# reshap this age vector\n",
    "Age = np.reshape(Age, [3,1])\n",
    "print(Age)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    Name  Age\n",
      "0    Ali   25\n",
      "1    Bob   24\n",
      "2  Chirs   29\n",
      "[25. 24. 29.]\n",
      "[[25.]\n",
      " [24.]\n",
      " [29.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find more operation about Pandas in the [documentation](https://pandas.pydata.org/) and [cheatsheet](https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read Matlab file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The functions --scipy.io.loadmat-- and --scipy.io.savemat-- allow you to read and write MATLAB files. You can read about them in the [documentation](https://docs.scipy.org/doc/scipy/reference/io.html)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "data = loadmat(\"../data/files/magic.mat\");\n",
    "print(data);\n",
    "print(data['magic'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Sun Jan 28 21:23:19 2018', '__version__': '1.0', '__globals__': [], 'magic': array([[17, 24,  1,  8, 15],\n",
      "       [23,  5,  7, 14, 16],\n",
      "       [ 4,  6, 13, 20, 22],\n",
      "       [10, 12, 19, 21,  3],\n",
      "       [11, 18, 25,  2,  9]], dtype=uint8)}\n",
      "[[17 24  1  8 15]\n",
      " [23  5  7 14 16]\n",
      " [ 4  6 13 20 22]\n",
      " [10 12 19 21  3]\n",
      " [11 18 25  2  9]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write Matlab file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X = np.array(data['magic'])\n",
    "# Do some calculation\n",
    "X = X*2\n",
    "# Dictionary from which to save matfile variables.\n",
    "data = {'magic2': X}\n",
    "# save the data\n",
    "savemat(\"../data/files/magic2.mat\", data)\n",
    "# Go to matlab and check the data\n",
    "\n",
    "data = loadmat(\"../data/files/magic2.mat\");\n",
    "print(data['magic2'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[34 48  2 16 30]\n",
      " [46 10 14 28 32]\n",
      " [ 8 12 26 40 44]\n",
      " [20 24 38 42  6]\n",
      " [22 36 50  4 18]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save and Load file by Pickle"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Pickle pacakge is used for serializing and de-serializing a Python object structure. Any object in python can be pickled so that it can be saved on disk and loaded back to continue the work. \n",
    "You can read about them in the [documentation](https://docs.python.org/3.6/library/pickle.html?highlight=pickle#module-pickle)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "X = np.eye(5)\n",
    "print(X)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Save the matirx X\n",
    "with open('../data/files/X.pickle', 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "# Change the value of the original X    \n",
    "X =  X + 4\n",
    "print(X)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[5. 4. 4. 4. 4.]\n",
      " [4. 5. 4. 4. 4.]\n",
      " [4. 4. 5. 4. 4.]\n",
      " [4. 4. 4. 5. 4.]\n",
      " [4. 4. 4. 4. 5.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# load the matrix \n",
    "with open('files/X.pickle', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "print(X)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One Example "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this demonstration, we will use a Logistic Regression Model and the Iris dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.datasets import load_iris  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and split data\n",
    "data = load_iris()  \n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(data.data, data.target, test_size=0.3, random_state=4)  \n",
    "\n",
    "# Create a model\n",
    "model = LogisticRegression(C=0.1,  \n",
    "                           max_iter=2000, \n",
    "                           fit_intercept=True \n",
    "                           )\n",
    "model.fit(Xtrain, Ytrain)  \n",
    "print(model);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression(C=0.1, max_iter=2000)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following few lines of code, the model which we created in the previous step is saved to file, and then loaded as a new object called pickled_model. The loaded model is then used to calculate the accuracy score and predict outcomes on new unseen (test) data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import pickle\n",
    "\n",
    "#\n",
    "# Create your model here (same as above)\n",
    "#\n",
    "\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = \"../data/pickle_model.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Load from file\n",
    "with open(pkl_filename, 'rb') as file:  \n",
    "    pickle_model = pickle.load(file)\n",
    "\n",
    "# Calculate the accuracy score and predict target values\n",
    "score = pickle_model.score(Xtest, Ytest)  \n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "Ypredict = pickle_model.predict(Xtest)  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 97.78 %\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use python to read and write the `yaml` file."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import yaml\n",
    "yaml_url = \"../data/test.yaml\"\n",
    "with open(yaml_url, encoding='utf-8') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "    print(data)\n",
    "    print(data['case1']['json'])\n",
    "    print(data['case1']['json']['username'])\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'case1': {'info': {'title': '正常登陆', 'url': 'http://192.168.1.1/user/login', 'method': 'POST'}, 'json': {'username': 'admin', 'password': '123456'}, 'expected': {'status_code': [200, 300], 'content': 'user_id'}}}\n",
      "{'username': 'admin', 'password': '123456'}\n",
      "admin\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import yaml\n",
    "\n",
    "content = {\n",
    "    'id': 1,\n",
    "    'text': 'programming languages',\n",
    "    'members': ['java', 'python', 'python', 'c', 'go', 'shell'],\n",
    "    'next': {'a':1,'b':2}\n",
    "}\n",
    "\n",
    "save_path = '../data/test_save.yaml'\n",
    "with open(save_path, 'w', encoding='utf-8') as file:\n",
    "    yaml.dump(content, file, default_flow_style=False, encoding='utf-8', allow_unicode=True)\n",
    "\n",
    "with open(save_path, encoding='utf-8') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "    print(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'id': 1, 'members': ['java', 'python', 'python', 'c', 'go', 'shell'], 'next': {'a': 1, 'b': 2}, 'text': 'programming languages'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# import pyyaml module\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "# Open the file and load the file\n",
    "with open(save_path) as f:\n",
    "    data = yaml.load(f, Loader=SafeLoader)\n",
    "    print(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'id': 1, 'members': ['java', 'python', 'python', 'c', 'go', 'shell'], 'next': {'a': 1, 'b': 2}, 'text': 'programming languages'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import yaml\n",
    "\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "with open(save_path, 'r') as f:\n",
    "    data = list(yaml.load_all(f, Loader=SafeLoader))\n",
    "    print(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'id': 1, 'members': ['java', 'python', 'python', 'c', 'go', 'shell'], 'next': {'a': 1, 'b': 2}, 'text': 'programming languages'}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import yaml\n",
    "\n",
    "# dict object\n",
    "members = [{'name': 'Zoey', 'occupation': 'Doctor'},\n",
    "           {'name': 'Zaara', 'occupation': 'Dentist'}]\n",
    "\n",
    "# Convert Python dictionary into a YAML document\n",
    "print(yaml.dump(members))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- name: Zoey\n",
      "  occupation: Doctor\n",
      "- name: Zaara\n",
      "  occupation: Dentist\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import yaml\n",
    "\n",
    "save_path = '../data/model_config.yaml'\n",
    "\n",
    "user_details = { 'model_name':'vgg19',\n",
    "                'w1': [1, 2, 3, 4, 5.0],\n",
    "                'AccessKeys': ['EmployeeTable',\n",
    "                               'SoftwaresList',\n",
    "                               'HardwareList']}\n",
    "\n",
    "with open(save_path, 'w') as f:\n",
    "    data = yaml.dump(user_details, f, sort_keys=False, default_flow_style=False)\n",
    "\n",
    "with open(save_path, 'r') as f:\n",
    "    # data = yaml.load_all(f, Loader=SafeLoader)\n",
    "    data = yaml.safe_load(f)\n",
    "    print(data)    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'model_name': 'vgg19', 'w1': [1, 2, 3, 4, 5.0], 'AccessKeys': ['EmployeeTable', 'SoftwaresList', 'HardwareList']}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "type(data['w1'])\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "67d32777f905cb443c7595cdac206bb322335f5bfbf8ae9544bce83f7472f717"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}